{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388b74a-2370-480b-a417-2dd68fdd2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initially, I attempted to use LangChain, but I found that the results were not as satisfactory as I had hoped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db02e43d-a5f5-4a5c-80f8-abcfc2d5c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader  #for textfiles\n",
    "from langchain.text_splitter import CharacterTextSplitter #text splitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings #for using HugginFace models\n",
    "from langchain.vectorstores import FAISS  \n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.document_loaders import UnstructuredPDFLoader  #load pdf\n",
    "from langchain.indexes import VectorstoreIndexCreator #vectorize db index with chromadb\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import UnstructuredURLLoader  #load urls into docoument-loader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94e7a8c-6dc7-458e-b2f2-45ca0886aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"uploads/CASE OF ANAGNOSTAKIS v. GREECE.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a202a1d8-fac1-4234-9786-8af6dd23b980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=64,\n",
    "    separators=['\\n\\n', '\\n', '(?=>\\. )', ' ', '']\n",
    ")\n",
    "docs  = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f6ab50-8e49-4e89-9d84-2206da7a0802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48faea8-8d75-4786-a14f-5f7450eca249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "177d1bf2-056d-469d-bcbd-7954e5e4e6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the Court of Appeal rejected the applicant’s and E.K.’s appeals regarding custody'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":1, \"max_length\":1000000})\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "query = \"What was the outcome for the alleged violation of Article 8 in the case of ANAGNOSTAKIS v. GREECE?\"\n",
    "docs = db.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb22019-ec34-46df-9c46-367b569fce7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In this case, I took a different approach. I preprocessed the data and fine-tuned my large language model using CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c61076-be43-482f-aba5-639e37cf188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4542ac0-fe7f-4d60-9386-ae9debd0de8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tokenized\\\\tokenizer_config.json',\n",
       " 'tokenized\\\\special_tokens_map.json',\n",
       " 'tokenized\\\\spiece.model',\n",
       " 'tokenized\\\\added_tokens.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Load the JSON data\n",
    "with open('datageece.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessed_data = []\n",
    "for item in data['data']:\n",
    "    context = item['context']\n",
    "    tokenized_context = tokenizer.encode(context, max_length=512, padding='max_length', truncation=True, return_tensors='pt').squeeze()\n",
    "\n",
    "    qas = []\n",
    "    for qa in item['qas']:\n",
    "        question = qa['question']\n",
    "        answer = qa['answer']\n",
    "        tokenized_question = tokenizer.encode(question, max_length=64, padding='max_length', truncation=True, return_tensors='pt').squeeze()\n",
    "        tokenized_answer = tokenizer.encode(answer, max_length=512, padding='max_length', truncation=True, return_tensors='pt').squeeze()\n",
    "        qas.append({\"question\": tokenized_question.tolist(), \"answer\": tokenized_answer.tolist()})\n",
    "\n",
    "    preprocessed_data.append({\"context\": tokenized_context.tolist(), \"qas\": qas})\n",
    "\n",
    "# Save the preprocessed data to a new JSON file\n",
    "with open('cleaned_final.json', 'w') as f:\n",
    "    json.dump(preprocessed_data, f)\n",
    "\n",
    "# Optionally, you can also save the tokenizer configuration\n",
    "tokenizer.save_pretrained('tokenized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6e43bd-1f60-498b-b0e7-d70fdc7c0156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 11.8\n",
      "PyTorch Version: 2.0.1+cu118\n",
      "tensor([ 8., 16., 24.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Print CUDA version\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "    # Print PyTorch version\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "    # Create a tensor on CUDA\n",
    "    a = torch.tensor([1.0, 2.0, 3.0], device=torch.device('cuda'))\n",
    "\n",
    "    # Perform a simple operation\n",
    "    b = a * 8\n",
    "\n",
    "    # Move the tensor back to CPU and print the result\n",
    "    print(b.cpu())\n",
    "else:\n",
    "    print(\"CUDA is not available. Please make sure you have CUDA-enabled GPU and have installed CUDA toolkit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19bea454-3f15-4a93-bd50-a16d5bd48604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615fad3f-a530-4021-9d21-1838fbc110e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f29f66f-2749-443d-a02b-27cceb9bd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "foo = torch.tensor([1,2,3])\n",
    "foo = foo.to('cuda')\n",
    "#this ran so not an issue w installation anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae18c14c-4fe6-4f8a-aea3-37deaebb7eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c981ec6b7a0e46f49aeb2561e1f652e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# outputs = model(**batch, labels=batch[\"input_ids\"])\u001b[39;00m\n\u001b[0;32m     91\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 92\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\n\u001b[0;32m     93\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "# from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# model_name = \"google/flan-t5-xl\"\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# class QADataSet(Dataset):\n",
    "#     def __init__(self, questions, answers, tokenizer, max_length=32):\n",
    "#         self.questions = questions\n",
    "#         self.answers = answers\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.questions)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         question = self.questions[idx]\n",
    "#         answer = self.answers[idx]\n",
    "\n",
    "#         input_text = \"question: {} context: {}\".format(question, answer)\n",
    "#         target_text = answer\n",
    "\n",
    "#         input_ids = self.tokenizer.encode(input_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "#         target_ids = self.tokenizer.encode(target_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "#         return {\n",
    "#             \"input_ids\": input_ids.flatten(),\n",
    "#             \"labels\": target_ids.flatten()\n",
    "#         }\n",
    "# questions = [\n",
    "#     \"What does Article 232 (a) of the Criminal Code relate to in this case?\",\n",
    "#     \"What did the applicant refuse regarding the psychiatric evaluation of the child?\",\n",
    "#     \"How did the applicant want the psychiatric evaluation to focus?\",\n",
    "#     \"What steps were taken by the public prosecutor to address the case?\",\n",
    "#     \"What was the Greek Ombudsman's role in this case?\",\n",
    "#     \"Why is the involvement of child-psychology experts considered important in contact disputes?\",\n",
    "#     \"How did the applicant's refusal to cooperate affect the case?\",\n",
    "#     \"What are the obligations of the State under Article 8 of the Convention in cases involving family life?\",\n",
    "#     \"What is the significance of a final court decision in this case?\",\n",
    "#     \"Why is the relationship between parents described as tense in the judgment?\",\n",
    "#     \"What principles guide the State's obligations in cases where children resist contact with a parent?\",\n",
    "#     \"How does the judgment view the necessity of cooperation in contact disputes?\",\n",
    "#     \"What are some examples of practical preparatory measures to facilitate contact between a parent and child?\",\n",
    "#     \"What is the primary consideration when determining the best interests of the child?\",\n",
    "#     \"How can the State balance the rights of parents and the best interests of the child in such cases?\",\n",
    "#     \"What is the significance of the Court's reference to Article 45 § 2 of the Convention in the judgment?\",\n",
    "#     \"In which cases may Article 8 of the Convention require phased measures?\",\n",
    "#     \"What role do child professionals and experts play in cases where children resist contact with a parent?\"\n",
    "#     \"What was the outcome for the alleged violation of Article 8 in the case of ANAGNOSTAKIS v. GREECE?\"\n",
    "# ]\n",
    "\n",
    "# answers = [\n",
    "#     \"Article 232 (a) of the Criminal Code is mentioned in the case as a provision that may be used to initiate criminal proceedings related to the child's refusal to meet with the applicant.\",\n",
    "#     \"The applicant refused to attend the psychiatric evaluation of the child and requested that the order be revoked because he was not consulted prior to the decision.\",\n",
    "#     \"The applicant wanted the psychiatric evaluation to focus on the specific reasons behind the child's refusal to meet with him.\",\n",
    "#     \"The public prosecutor ordered social reports, a psychiatric evaluation, and referred the case to GONIS for consultation.\",\n",
    "#     \"The Greek Ombudsman contacted E.K., made recommendations, and suggested alternatives to GONIS for resolving the contact issue.\",\n",
    "#     \"In contact disputes, child-psychology experts can help identify and address the reasons behind a child's refusal to meet with a parent, contributing to resolution.\",\n",
    "#     \"The applicant's refusal to cooperate, including his refusal to attend the psychiatric evaluation and consider counseling, hindered efforts to resolve the contact issue.\",\n",
    "#     \"Under Article 8 of the Convention, the State has positive obligations to facilitate and maintain family life, including taking practical measures to resolve disputes.\",\n",
    "#     \"The final court decision of the Athens Court of First Instance granted contact rights to the applicant, making it a crucial element in the case.\",\n",
    "#     \"The relationship between the parents is described as tense in the judgment because it was characterized by mistrust and rivalry, which impacted the child's refusal to meet the applicant.\",\n",
    "#     \"States are guided by principles that require them to identify the causes of the child's resistance and take appropriate measures to address those causes.\",\n",
    "#     \"The judgment emphasizes the importance of cooperation and understanding among all parties involved in contact disputes.\",\n",
    "#     \"Practical preparatory measures may include counseling, mediation, gradual reintroduction plans, and emotional and psychological support for all parties involved.\",\n",
    "#     \"The best interests of the child are the primary consideration, ensuring that decisions and measures taken aim to benefit the child's well-being.\",\n",
    "#     \"The State must strike a balance between respecting the rights of parents and safeguarding the best interests of the child when addressing contact disputes.\",\n",
    "#     \"Article 45 § 2 of the Convention allows for the attachment of separate opinions to judgments, as seen in the dissenting opinion of Judge Serghides.\",\n",
    "#     \"Article 8 of the Convention may require phased measures in cases where reunification of a parent and child needs gradual and systematic reintroduction.\",\n",
    "#     \"Child professionals and experts play a vital role in assessing and addressing the child's needs and reasons for resisting contact, helping find solutions.\"\n",
    "#     \"The Court found no violation of Article 8 of the Convention in the case of ANAGNOSTAKIS v. GREECE. This is stated in paragraph 68 of the judgment.\"\n",
    "#     \"Article 8 (right to respect for private and family life) of the Convention was alleged to have been violated in the case of ANAGNOSTAKIS v. GREECE. This is stated in paragraph 38 of the judgment.\"\n",
    "# ]\n",
    "# dataset = QADataSet(questions, answers, tokenizer)\n",
    "# inputs = tokenizer(questions, answers, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "# data_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=1000)\n",
    "\n",
    "# num_epochs = 3\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     for batch in data_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         # outputs = model(**batch, labels=batch[\"input_ids\"])\n",
    "#         labels = batch[\"labels\"].to(device)\n",
    "#         loss = labels.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "# model.save_pretrained(\"fine_tuned_flan_t5\", save_tokenzing_model=True)\n",
    "# tokenizer.save_pretrained(\"fine_tuned_flan_t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d2e02-cd58-4c32-b1b1-9db118c111dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the code blocks below, I trained and tested several fine-tuned models using data preprocessed in various ways. The results can be found at the bottom of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577bea35-a94c-4ab3-a53b-8d6084b17f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/3:   4%|██▌                                                                   | 29/799 [00:07<03:18,  3.88it/s]C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:309: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "Epoch 1/3: 100%|█████████████████████████████████████████████████████████████████████| 799/799 [03:28<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|█████████████████████████████████████████████████████████████████████| 799/799 [03:27<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|█████████████████████████████████████████████████████████████████████| 799/799 [03:27<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('cleaned_fine_tuned_vector\\\\tokenizer_config.json',\n",
       " 'cleaned_fine_tuned_vector\\\\special_tokens_map.json',\n",
       " 'cleaned_fine_tuned_vector\\\\spiece.model',\n",
       " 'cleaned_fine_tuned_vector\\\\added_tokens.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class QADataSet(Dataset):\n",
    "    def __init__(self, questions, answers, tokenizer, max_length=32):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "\n",
    "        input_text = \"question: {} context: {}\".format(question, answer)\n",
    "        target_text = answer\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        target_ids = self.tokenizer.encode(target_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids.flatten(),\n",
    "            \"labels\": target_ids.flatten()\n",
    "        }\n",
    "\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "file_path = \"cleaned_final.json\"\n",
    "\n",
    "# Lists to store questions and answers\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(file_path, 'r',  encoding=\"utf8\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract questions and answers\n",
    "for item in json_data:\n",
    "    for qa in item['qas']:\n",
    "        questions.append(qa['question'])\n",
    "        answers.append(qa['answer'])\n",
    "\n",
    "dataset = QADataSet(questions, answers, tokenizer)\n",
    "batch_size = 1\n",
    "gradient_accumulations = 1600\n",
    "effective_batch_size = batch_size * gradient_accumulations\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(data_loader) * num_epochs)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Automatic mixed precision training\n",
    "        with autocast():\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss / gradient_accumulations).backward()\n",
    "\n",
    "        if (batch_idx + 1) % gradient_accumulations == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(data_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}\")\n",
    "\n",
    "model.save_pretrained(\"cleaned_fine_tuned_vector\", save_tokenizer=True)\n",
    "tokenizer.save_pretrained(\"cleaned_fine_tuned_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d7099a-809e-4d4d-a070-9f41e9e59f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/3: 100%|███████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|███████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|███████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fine_tuned_vector2\\\\tokenizer_config.json',\n",
       " 'fine_tuned_vector2\\\\special_tokens_map.json',\n",
       " 'fine_tuned_vector2\\\\spiece.model',\n",
       " 'fine_tuned_vector2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class QADataSet(Dataset):\n",
    "    def __init__(self, questions, answers, tokenizer, max_length=32):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "\n",
    "        input_text = \"question: {} context: {}\".format(question, answer)\n",
    "        target_text = answer\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        target_ids = self.tokenizer.encode(target_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids.flatten(),\n",
    "            \"labels\": target_ids.flatten()\n",
    "        }\n",
    "\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "file_path = \"KEERA.json\"\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(file_path, 'r',  encoding=\"utf8\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "for item in json_data[\"data\"]:\n",
    "    for qa in item['qas']:\n",
    "        questions.append(qa['question'])\n",
    "        answers.append(qa['answer'])\n",
    "dataset = QADataSet(questions, answers, tokenizer)\n",
    "batch_size = 1\n",
    "gradient_accumulations = 160\n",
    "effective_batch_size = batch_size * gradient_accumulations\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(data_loader) * num_epochs)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Automatic mixed precision training\n",
    "        with autocast():\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss / gradient_accumulations).backward()\n",
    "\n",
    "        if (batch_idx + 1) % gradient_accumulations == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(data_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}\")\n",
    "\n",
    "model.save_pretrained(\"fine_tuned_vector2\", save_tokenizer=True)\n",
    "tokenizer.save_pretrained(\"fine_tuned_vector2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f153770-aef6-4e36-b656-8a5dc628d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc023b7-8809-4bf9-b306-2589cd1c6259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the central issue in the case?\n",
      "Answer: Non-enforcement of judicial decisions granting applicant contact rights with his child applicant’s unaccommodating conduct Article 34 of the Convention for the Protection of Human Rights and Fundamental Freedoms lack of assistance of the domestic authorities in respect of the enforcement of court decisions setting the contact schedule between the applicant and his child non-enforcement of court decisions the authorities had not been sufficiently active in helping him restore his relationship with his child delay in the proceedings setting the contact schedule between the applicant and his child child was theirs. E.K. and the child continued to live with his mother child refused to accompany the applicant when he arrived to pick him up shared custody between the parents alimony weekends per month the applicant would also spend on an alternate basis, Christmas, Easter and summer vacations with his child shared custody the relationship between the parents was very tense custody had not been open to appeal impossibility of lodging an appeal acted against the applicant his son in accordance with the schedule agreed with the mother the mother had refused to allow him to compensate for the time lost with their child the prosecutor order a psychiatric evaluation of the child the child’s living conditions parental issues determining the issue of custody the applicant appeared to care about and love his son the child’s living conditions with his mother to request that she not influence the child negatively in that regard issue of contact with his father licant and their child ents initially participated separately in consultations with the experts of the association another social report be drawn up on the child’s living conditions with his mother the child refused to accompany him for their contact his continued refusal to meet with his father the Centre not being consulted prior to its adoption psychiatric evaluation the child to be compelled to attend 232 (a) of the Criminal Code refusal to meet with his father the applicant had refused to participate in the sessions GONIS had proposed that undermined his right to contact with his child the recommendations which were in breach of the court decisions contact with his child revoke the order for consultations with the GONIS organisation refusals of his child to accompany him breach of a court decision mother had been impeding communication communication father his young age, it was the child who refused to meet with his father parental cooperation through the GONIS org anisation mishandling of the child intervention of mental health experts would be useful contact rights with his child right to respect for his private and family life ANAGNOSTAKIS v. GREECE parental responsibility parent residing with the child had impeded the other parent’s communication could not order the necessary measures execution of civil decisions the issue of alternate custody respect for equality between the parents the communication between a parent and a child adequacy of domestic remedies in the field of communication between children and their parents contact rights with his child requirement to exhaust domestic remedies ineffective the application was premature the application is neither manifestly ill-founded nor inadmissible on any other grounds It must therefore be declared admissible The root cause had been incitement by the mother best interests of the child inciting the child to refuse communication The issue that should have been examined was the cause of the child’s refusal to accept communication with the applicant absence of cooperation on the part of the mother and the child’s refusal to meet with him family ties between the applicant and his child custody and contact rights of parents with their children restore communication between the applicant and his child the child’s mother parents and their respective families two parents had not collaborated at all with each other or the experts the child and his needs the mother to cooperate non-enforcement of judicial decisions whereby the applicant was granted contact rights the State’s positive obligation maintain the relationship between the applicant and his son The adequacy of the measures Article 8 of the Convention requires States to try to identify the causes of such resistance and address them accordingly cooperation and understanding of all concerned right of a child to express his or her own views parents keeping in mind the paramount interests of the child the intensive litigation between the applicant and the mother of his child had alre he had been unable to see his child in accordance with the agreed schedule contact dispute one or both parents’ behaviour is far from constructive the applicant’s recourse to the domestic courts the applicant and his child would fade parents’ very poor relationship cooperation between separated parents best interests of the child and his or her rights his resistance to meeting with the applicant the applicant could maintain his relationship with his son GONIS reason for initiating criminal proceedings under Article 232 (a) of the Criminal Code the Centre the mother’s behaviour restoration of their contact the applicant’s communication with the child the domestic authorities’ efforts were in vain the order should have been given with specific instructions Greek Ombudsman his child’s refusal to meet with him communication with his child the failure to enforce the applicant’s contact rights Article 8 of the Convention non-enforcement of a decision Court of Appeal violation of Article 8 of the Convention Finland and the Republic of Cyprus separation of parents contact between the father and the child the applicant did not trust that organisation However, no proposal was made by the Greek Ombudsman as to counselling and psychological or emotional support for the child the Greek Ombudsman to contact organisations specialising in children’s mental health the mother, whose participation was a prerequisite for the intervention his recommendation the involvement of child-psychology experts the domestic authorities should have proposed consultation with another organisation, public or private, but they omitted to do so the prosecution held a joint consultation with both parents able to take place immediately ed ANAGNOSTAKIS v. GREECE contact hours no preparatory measures were taken whether the authorities have indeed taken and implemented such preparatory measures reintroduction plan restoration of contact between the father and his son forcement the judgment is inconsistent whether the domestic authorities took all necessary steps that could reasonably be demanded in the specific circumstances the passage of time could have irremediable consequences for relations between the applicant and his son failure to enforce the applicant’s contact rights cause of the child’s resistance to contact with his father cooperation and understanding of all concerned mistrust and intense rivalry child child-friendly justice riend Article 8 just satisfaction\n",
      "\n",
      "Question: What is the case of ANAGNOSTAKIS v. GREECE about?\n",
      "Answer: contact rights with his child not attributed to a lack of diligence on the part of the relevant authorities Anagnostakis v. Greece Human Rights and Fundamental Freedoms the Greek Government (“the Government”) non-enforcement of court decisions the mother had alienated the child from him Ms O. Patsopoulou E.K. was the father of the child. E.K. and the child child refused to accompany the applicant child’s name alimony weekends decision no. 585/2018 child’s best interests custody and the education of their child custody criminal proceedings defamatory social services time lost with their child psychiatric evaluation of the child a child’s living conditions social services g conditions of the child social worker custody and the contact rights summoned issue of contact with his father licant and their child ents initially participated separately in consultations with the experts of the association child’s living conditions reaso psychiatric evaluation of the child GREECE revoke the order psychiatric a copy a) of the Criminal Code the Centre for Mental Health a child ANAGNOSTAKIS v. GREECE contact rights court proceedings concerning custody contact with his child GONIS organisation rt of First Instance breach of a court decision contact rights with his child facilitating communication father the Ombudsman parental cooperation through the GONIS org anisation c mishandling of the child intervention of mental health experts would be useful right to respect for his family public authority with the exercise of this right domestic remedies parental responsibility judges dealing with family-law cases were experienced judges specialised in that field who could freely assess all the evidence, including the child’s opinion, domestic law execution of a civil decision req the Court was in general better placed than the Court to evaluate the elements in the file. ANAGNOSTAKIS domestic court’s decisions regarding his rights of visitation contact rights with his child requirement to exhaust domestic remedies Article 1532 of the Civil Code civil code contact rights It must therefore be declared admissible child’s negative attitude towards him order had not specified its objectives psychiatric evaluation case law child’s refusal to meet with him, or to act in the child’s best interests family ties parental responsibility, including custody and contact rights of parents with their children restore communication between the applicant and his child child’s mother Ombudsman collaboration mental health omissions non-enforcement of judicial decisions the State’s positive obligation under Article 8 of the Convention the Court’s task 13 domestic decisions the present one, where children resist contact with one parent cooperation and understanding right parents ties hts ady domestic courts court order where one or both parents’ behaviour is far from constructive enabling the applicant’s contact with his son contact with their parents contact coercion the prosecutor in the period from 2016 to 2019 psychiatric evaluation the applicant could maintain his relationship with his son GONIS public prosecutor in charge of criminal proceedings Centre child’s refusal the applicant’s complaint public law organisations specialised in children’s mental health psychiatric evaluation of the child child’s refusal to meet with him GREECE child’s refusal to meet with him child-psychology experts contact rights Article 8 non-enforcement of a decision Court of Appeal Convention Greece and the European Union separation of parents psychiatric evaluation non- governmental organisation GONIS children’s mental health the Greek Ombudsman the intervention was a prerequisite for the intervention Ombudsman child-psychology experts consultation with the non-governmental organisation GONIS did not work joint consultation with both parents measures being taken to this effect ed measures child psychology contact hours no preparatory measures were taken re- establishment of contact between the father and son preparatory measures enforcement of the decision forcement the requirement of preparatory measures iv. relations between the applicant and his son contact rights child’s resistance to contact a primary consideration the relationship between the parents child-centred child-friendly justice riend violation of Article 8 just satisfaction\n",
      "\n",
      "Question: What does Article 232 (a) of the Criminal Code relate to in this case\n",
      "Answer: Non-enforcement of judicial decisions 2 of the Convention application (no. 26504/20) violation of the rights of a child non-enforcement alienating the child 232 (a) of the Criminal Code child was theirs. E.K. and the child domestic proceedings alimony and contact hours alimony weekends decision no. 585/2018 is not in the best interests of the child child abuse custody breach of a domestic decisi defamatory travelling lost with their child a psychiatric evaluation of the child a child child to the domestic courts in charge of determining the issue of custody a criminal offence a request summoned contact with his father parents consultations were ultimately discontinued disciplinary proceedings for the intervention Refusal ealth (a) of the Criminal Code psychiatric evaluation a copy organisation would eventually conduct the evaluation refusal to meet with his father refusal to participate in the sessions and in the evaluation of the child the applicant pay a bribe contact with the child GONIS contact with his child Consultations with the GONIS organisation Refusal to accompany him offence impeding communication facilitating communication father communication with his child ally of the organisation anisation mishandling of the child communication with the child right to respect for his family life public authority with the exercise of this right for the protection of health or morals parental responsibility impeded the other parent’s communication plicant execution of civil decisions rematurely Article 232 (a) of the Criminal Code communication between a parent GNOSTAKIS contact rights with his child domestic remedies in Article 1532 of the Civil Code application omplaint child abuse incitement by the mother order by the prosecutor had not specified its objectives a specific objective 232 (a) absence of cooperation on the part of the mother family ties regulating the exercise of parental responsibility to restore communication the child’s mother o to establish a spirit committing a criminal offence omissions non-enforcement contact rights to maintain the relationship between the applicant and his son 58, Series A no. 299-A children resist contact with one parent co-operation rights parents ties hts complaints to the prosecutor contact dispute enforcement of a court order contact with his son contact with their parents any coercion the best interests of the child requests for the delivery of health records ANAGNOSTAKIS committing an offence initiating criminal proceedings the Centre child’s refusal to meet the child’s refusal to meet with t public law organisations specialised in children’s mental health psychiatric evaluation of the child revoke the order the Greek Ombudsman refusal to meet with him contact between the applicant and his son contact rights violation non-enforcement of a decision judgment violation of Article 8 measures taken to that end separation of parents more practical, effective and meaningful referral of the entire family to the non- governmental organisation GONIS child abuse child abuse (a) the Ombudsman Article 232 (a) of the Criminal Code omitted to do so Referral to GONIS measures being taken to this effect . reintroduction contact hours a child steadfastly declining contact with his father any measure entailing force preparatory measure paratory measure it regrettably omits to consider that in the present case no such measures were taken, and yet considers that the respondent State fulfilled Preparatory measures iv relations between the applicant and his son failure to enforce the applicant’s contact rights child’s resistance to contact cooperation and understanding of all concerned the child child child l violation of Article 8 Article 232 (a) of the Criminal Code\n",
      "\n",
      "Question: What does Article 8 of the Convention require States to do in cases where children resist contact with one parent?\n",
      "Answer: enforce Pere Pastor Vilanova, President, Geo contact with one parent give notice declare the remainder of the application inadmissible help him restore his relationship with his child set the contact schedule child would be raised by the applicant. the child and his mother contact with one parent shared custody between the parents share custody weekends per month with two overnight stays spend on an alternate basis would not serve the child exercise of custody and the education custody lodge an appeal prosecutor contact with the child compensate for the time lost a psychiatric evaluation of the child both parents should be referred consult the appropriate authorities on 26 May 2018. order another social report transmit the two social reports make recommendations to her to facilitate the communication joint consultation consult with both parents consultations were ultimately discontinued social report ascertain the conditions under which the child refused psychiatric evaluation the Centre consulted psychiatric evaluation provide a copy initiate an investigation into an offence conduct an assessment evaluate the child GONIS be disbanded. meet together custody contact with his child Consult the GONIS organisation recorded with the registry of Incidents and O assist him contacted the mother facilitating communication mother contact the GONIS organisation alternate custody anisation restoration of the communication intervention of mental health experts respect for his family life interference by a public authority for the protection of health or morals remove, fully or partially, parental responsibility from the parent order any necessary measures order the necessary measures execute a decision regulating the contact rights of a parent with his or her child alternate custody examine the case, having as their primary consideration the child’s best interests measure provided for in Article 1532 enforcement of the domestic court’s decisions regarding his rights of visitation contact rights with his child exhaust domestic remedies in Article 1532 of the Civil Code provide any redress contact schedule effective intervention address the causes order by the prosecutor had not specified its objectives. conciliation procedure or joint session with the social services evaluate act in the child’s best interests family ties remedying restore communication between the applicant and his child meetings had been held with both parents judge or instruct the parents collaborate with each other consults omit to take non-enforcement establish regular and meaningful contact with him take all necessary steps swiftness of their implementation try to identify the causes of such resistance take preparatory or phased measures examine take measures to reconcile keeping in mind the paramount interests of the child which, depending on their nature and seriousness, may override those of the parent enforce comply with the agreed schedule transmitting the relevant results enforce a court order contact with his son phased measures set out by the domestic courts coercion best interests of the child and his or her rights psychiatric evaluation of the child by experts provide assistance referred the entire family to GONIS for consultation initiate criminal proceedings the Centre meet with the child restore their contact public law organisations specialised in children’s mental health domestic authorities’ efforts were in vain a psychiatric evaluation Greek Ombudsman addressing the root causes involvement of child-psychology experts enforce the applicant’s contact rights contact enforce Court of Appeal restore contact between a parent and a child States should not be regarded as a detriment to the rights of the child e separated parents psychiatric evaluation referral of the entire family to the non- governmental organisation GONIS for consultation counselling and psychological or emotional support 19 organisations specialising in children’s mental health intervene contact with one parent counselling and psychological or emotional support consultation with another organisation, public or private joint consultation with both parents measures being taken to this effect ed arranged in playgrounds in the presence of persons whom the child can trust contact hours measure or combination of measures should be taken consider the necessity of preparatory measures preparatory measures restoration of contact forcement such measures take all necessary steps that could reasonably be demanded the passage of time could have irremediable consequences for relations between the applicant and his son try to identify the causes psychological evaluation authorities must keep in mind take as a primary consideration intervention by the State walk beside me riend contact with one parent a).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import fitz  # PyMuPDF\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = \"fine_tuned_vector\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "pdf_path = \"uploads/CASE OF ANAGNOSTAKIS v. GREECE.pdf\"\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "text = \"\"\n",
    "for page_num in range(pdf_document.page_count):\n",
    "    page = pdf_document.load_page(page_num)\n",
    "    text += page.get_text()\n",
    "\n",
    "max_sequence_length = tokenizer.model_max_length\n",
    "chunk_size = 400  # Adjust as needed\n",
    "text_chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "questions = [\n",
    "    \"What is the central issue in the case?\",\n",
    "    \"What is the case of ANAGNOSTAKIS v. GREECE about?\", \n",
    "    \"What does Article 232 (a) of the Criminal Code relate to in this case\",\n",
    "    \"What does Article 8 of the Convention require States to do in cases where children resist contact with one parent?\"\n",
    "]\n",
    "\n",
    "# Generate answers using the GPU\n",
    "for question in questions:\n",
    "    answers = []\n",
    "    for chunk in text_chunks:\n",
    "        input_text = f\"question: {question} context: {chunk}\"\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=max_sequence_length).to(device)\n",
    "        outputs = model.generate(input_ids=input_ids, max_length=32, num_beams=4, early_stopping=True)\n",
    "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        answers.append(answer)\n",
    "    \n",
    "    combined_answer = \" \".join(answers)\n",
    "    print(f\"Question: {question}\\nAnswer: {combined_answer}\\n\")\n",
    "\n",
    "pdf_document.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a242bfc-ec8d-4cb6-8531-3f4fe3afb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d524aa4e-e87f-43de-9d8a-cbbe5d5cd2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import fitz  \n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = \"cleaned_fine_tuned_vector\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2fab056-94a4-4cef-84ca-4929e1a70514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What article of the Convention was alleged to have been violated in the case of ANAGNOSTAKIS v. GREECE?\n",
      "Answer: Art 8 • Positive obligations • Family life • Non-enforcement of judicial decisions granting applicant contact rights with his child not attributed to a lack of diligence on the part of the relevant authorities • Authorities’ efforts in vain owing to tense relationship between parents and their behaviour, including applicant’s unaccommodating conduct STRASBOURG 10 October 2023 This judgment will become final in the circumstances set out in Article 44  2 of the Convention. It may be subject to editorial revision. ANAGNOSTAKIS v. GREECE\n",
      "\n",
      "Question: Summarize the case in a few lines\n",
      "Answer: The European Court of Human Rights (Third Section), sitting as a Chamber composed of: Pere Pastor Vilanova, President, Georgios A. Serghides, Darian Pavli, Peeter Roosma, Ioannis Ktistakis, Andreas Zünd, Oddn Mjöll Arnardóttir, judges, and Milan Blako, Section Registrar, Having regard to: the application (no. 26504/20) against the Hellenic Republic lodged with the Court\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_path = \"uploads/CASE OF ANAGNOSTAKIS v. GREECE.pdf\"\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "text = \"\"\n",
    "for page_num in range(pdf_document.page_count):\n",
    "    page = pdf_document.load_page(page_num)\n",
    "    text += page.get_text()\n",
    "    \n",
    "max_sequence_length = tokenizer.model_max_length\n",
    "chunk_size = 400  # Adjust as needed\n",
    "text_chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "questions = [\n",
    "    \"What article of the Convention was alleged to have been violated in the case of ANAGNOSTAKIS v. GREECE?\",\n",
    "    \"Summarize the case in a few lines\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    input_text = f\"question: {question} context: {text}\"  \n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=max_sequence_length).to(device)\n",
    "    outputs = model.generate(input_ids=input_ids, max_length=128, min_length=100, num_beams=4, early_stopping=False)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Question: {question}\\nAnswer: {answer}\\n\")\n",
    "\n",
    "pdf_document.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
